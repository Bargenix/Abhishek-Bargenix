{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8a4868541de24c2ab571ef9208f2ded3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f2502722055f40e181a322f45ec97c5b",
              "IPY_MODEL_2e21356defaa419a9bdcd00e12ce28fb",
              "IPY_MODEL_1b5584f21de6448da72b2e4e0f629308"
            ],
            "layout": "IPY_MODEL_68e389ad7bb648e5abb2607668c3e1ba"
          }
        },
        "f2502722055f40e181a322f45ec97c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d18d4532990447778860e176a5f300f9",
            "placeholder": "​",
            "style": "IPY_MODEL_7f01d8a3e2c64c4bae6d04ccc27dfb1c",
            "value": "model.safetensors: 100%"
          }
        },
        "2e21356defaa419a9bdcd00e12ce28fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_774bc25cb2474b6d91c9bb1e333744fc",
            "max": 5702746403,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0f7c29124e594f1999971f950730a37e",
            "value": 5702746403
          }
        },
        "1b5584f21de6448da72b2e4e0f629308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e98759e710014e8493026c018305a82c",
            "placeholder": "​",
            "style": "IPY_MODEL_b831854978b64e72ab142eeb21f04b3d",
            "value": " 5.70G/5.70G [00:20&lt;00:00, 482MB/s]"
          }
        },
        "68e389ad7bb648e5abb2607668c3e1ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d18d4532990447778860e176a5f300f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f01d8a3e2c64c4bae6d04ccc27dfb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "774bc25cb2474b6d91c9bb1e333744fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f7c29124e594f1999971f950730a37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e98759e710014e8493026c018305a82c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b831854978b64e72ab142eeb21f04b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8f6a8d50ae34ddbbc2a8e4b1e57b390": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e8c7cdb006aa445dbaa89ed0e9e3dd8c",
              "IPY_MODEL_c0b7cae5946a4efaab280334f8156e09",
              "IPY_MODEL_82265314dc414406bb01aba60cbc146c"
            ],
            "layout": "IPY_MODEL_52e8b5a9b6f749d29c18e3897ce0ba9e"
          }
        },
        "e8c7cdb006aa445dbaa89ed0e9e3dd8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7a77bc1d4ac47078c006c656f597211",
            "placeholder": "​",
            "style": "IPY_MODEL_556a26633b7b4decb14d4aa64e60666b",
            "value": "generation_config.json: 100%"
          }
        },
        "c0b7cae5946a4efaab280334f8156e09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f826be8c208412dbfe08e3822abd7a1",
            "max": 220,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d21bdc445fd7424cb42c5f94a3544884",
            "value": 220
          }
        },
        "82265314dc414406bb01aba60cbc146c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6b957562dc254e898d40a580dd55cbda",
            "placeholder": "​",
            "style": "IPY_MODEL_a5efea9511684ca4bf0e69bdb37b9acd",
            "value": " 220/220 [00:00&lt;00:00, 26.2kB/s]"
          }
        },
        "52e8b5a9b6f749d29c18e3897ce0ba9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7a77bc1d4ac47078c006c656f597211": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556a26633b7b4decb14d4aa64e60666b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f826be8c208412dbfe08e3822abd7a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d21bdc445fd7424cb42c5f94a3544884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6b957562dc254e898d40a580dd55cbda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5efea9511684ca4bf0e69bdb37b9acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c9287998c4e149b6b4873dd59fcdc524": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73b362513ad843e6b159a90dfc5e2be6",
              "IPY_MODEL_388ec9199ab049b2a20b4c542320a0f3",
              "IPY_MODEL_d42cd20bafb54656b830d6fda2164cfc"
            ],
            "layout": "IPY_MODEL_ff756fea9c63445bb104cc08e2228365"
          }
        },
        "73b362513ad843e6b159a90dfc5e2be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b7ba7fb3fe04561b473c1afb8d918e5",
            "placeholder": "​",
            "style": "IPY_MODEL_acd9de881f194c69a8674a330b91c7b0",
            "value": "tokenizer_config.json: "
          }
        },
        "388ec9199ab049b2a20b4c542320a0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fe7f83921204c8298ca6afcca99aaf5",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b1912c81ff634e59ba0e06796d47f2bb",
            "value": 1
          }
        },
        "d42cd20bafb54656b830d6fda2164cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_31585124ac3b4d6e904c4b083195a7f0",
            "placeholder": "​",
            "style": "IPY_MODEL_7d292ff20ec04de095509a8bfaffbad0",
            "value": " 51.1k/? [00:00&lt;00:00, 6.31MB/s]"
          }
        },
        "ff756fea9c63445bb104cc08e2228365": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b7ba7fb3fe04561b473c1afb8d918e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acd9de881f194c69a8674a330b91c7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6fe7f83921204c8298ca6afcca99aaf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b1912c81ff634e59ba0e06796d47f2bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "31585124ac3b4d6e904c4b083195a7f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d292ff20ec04de095509a8bfaffbad0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c132260049d044b29bcfbd1e7f161acb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fe697789de0149239d06cda4ecccbc46",
              "IPY_MODEL_1601abe3c10145ecae8838bb72c96e67",
              "IPY_MODEL_296792ff81f742e69a573f9ad5ba5f3a"
            ],
            "layout": "IPY_MODEL_18b4b9e8628f47c5bcd884cac898dd3e"
          }
        },
        "fe697789de0149239d06cda4ecccbc46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4bc00ba35a24209b0223fc555b3d1eb",
            "placeholder": "​",
            "style": "IPY_MODEL_c96ce9068cb544d6b48ea5de8acf1888",
            "value": "tokenizer.json: "
          }
        },
        "1601abe3c10145ecae8838bb72c96e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ee7c186073740e59030a0e667b20b3b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4fd4ae1b89df419092c09240326d6aea",
            "value": 1
          }
        },
        "296792ff81f742e69a573f9ad5ba5f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fff2e203b434db39168e14bb2fc2070",
            "placeholder": "​",
            "style": "IPY_MODEL_34a6feb9c03b4539ae1017f90c53100a",
            "value": " 9.09M/? [00:00&lt;00:00, 144MB/s]"
          }
        },
        "18b4b9e8628f47c5bcd884cac898dd3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4bc00ba35a24209b0223fc555b3d1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c96ce9068cb544d6b48ea5de8acf1888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ee7c186073740e59030a0e667b20b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "4fd4ae1b89df419092c09240326d6aea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fff2e203b434db39168e14bb2fc2070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34a6feb9c03b4539ae1017f90c53100a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f68d76d59b84dfa93c2b25c134968e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_529a3d041edf4887a40737bb632159c3",
              "IPY_MODEL_1da9afdf6b284367be691a5c0c6a419d",
              "IPY_MODEL_4f0c6f5a1509461385578177d3f01a18"
            ],
            "layout": "IPY_MODEL_447a5476bb454c41b71e72b0b2c3c2f3"
          }
        },
        "529a3d041edf4887a40737bb632159c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2234c735e2f24d60b997fe365a429373",
            "placeholder": "​",
            "style": "IPY_MODEL_12128bf5b6d44eea8de95d22dd8bbc4d",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "1da9afdf6b284367be691a5c0c6a419d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25b5e47346fa4d4baf972f1961271795",
            "max": 345,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1cc8f0fc4ec247a3bf6eefb1f54354c0",
            "value": 345
          }
        },
        "4f0c6f5a1509461385578177d3f01a18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ae74afecd6c54baba4629930b76ae464",
            "placeholder": "​",
            "style": "IPY_MODEL_0f52ddefc6534640b86d022eaa32ba60",
            "value": " 345/345 [00:00&lt;00:00, 41.5kB/s]"
          }
        },
        "447a5476bb454c41b71e72b0b2c3c2f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2234c735e2f24d60b997fe365a429373": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12128bf5b6d44eea8de95d22dd8bbc4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "25b5e47346fa4d4baf972f1961271795": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cc8f0fc4ec247a3bf6eefb1f54354c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ae74afecd6c54baba4629930b76ae464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f52ddefc6534640b86d022eaa32ba60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install unsloth bitsandbytes transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sJFQpb_epa26",
        "outputId": "10f11596-9f85-4656-c305-1bf73a3bf6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting unsloth\n",
            "  Downloading unsloth-2025.6.12-py3-none-any.whl.metadata (46 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/46.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.9/46.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.0)\n",
            "Collecting unsloth_zoo>=2025.6.8 (from unsloth)\n",
            "  Downloading unsloth_zoo-2025.6.8-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: torch<=2.7.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.6.0+cu124)\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.31-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: triton>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (3.2.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from unsloth) (24.2)\n",
            "Collecting tyro (from unsloth)\n",
            "  Downloading tyro-0.9.26-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting datasets>=3.4.1 (from unsloth)\n",
            "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: sentencepiece>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from unsloth) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.9.5)\n",
            "Requirement already satisfied: wheel>=0.42.0 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.45.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from unsloth) (2.0.2)\n",
            "Requirement already satisfied: accelerate>=0.34.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (1.8.1)\n",
            "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,>=0.7.9 (from unsloth)\n",
            "  Downloading trl-0.19.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.15.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from unsloth) (5.29.5)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.33.1)\n",
            "Requirement already satisfied: hf_transfer in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.1.9)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.34.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from unsloth) (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets>=3.4.1->unsloth) (0.70.15)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub->unsloth) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.6.15)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<=2.7.0,>=2.4.0->unsloth) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<=2.7.0,>=2.4.0->unsloth) (1.3.0)\n",
            "Collecting protobuf (from unsloth)\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Collecting cut_cross_entropy (from unsloth_zoo>=2025.6.8->unsloth)\n",
            "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from unsloth_zoo>=2025.6.8->unsloth) (11.2.1)\n",
            "Collecting msgspec (from unsloth_zoo>=2025.6.8->unsloth)\n",
            "  Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
            "  Downloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting torch<=2.7.0,>=2.4.0 (from unsloth)\n",
            "  Downloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (29 kB)\n",
            "Collecting sympy>=1.13.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.6.80 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.5.1.17 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.1.0.70->torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.0.4 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.7.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.1.2 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.3 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.26.2 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.6.77 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.6.1.9->torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufile-cu12==1.11.1.6 (from torch<=2.7.0,>=2.4.0->unsloth)\n",
            "  Downloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton>=3.0.0 (from unsloth)\n",
            "  Downloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton>=3.0.0->unsloth) (75.2.0)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers->unsloth) (8.7.0)\n",
            "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchvision (from unsloth)\n",
            "  Downloading torchvision-0.22.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "  Downloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.15 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (13.9.4)\n",
            "Collecting shtab>=1.5.6 (from tyro->unsloth)\n",
            "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from tyro->unsloth) (4.4.4)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (3.11.15)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=11.1.0->tyro->unsloth) (2.19.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<=2.7.0,>=2.4.0->unsloth) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=3.4.1->unsloth) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth) (1.20.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro->unsloth) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth) (1.17.0)\n",
            "Downloading unsloth-2025.6.12-py3-none-any.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/294.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bitsandbytes-0.46.1-py3-none-manylinux_2_24_x86_64.whl (72.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 MB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.19.0-py3-none-any.whl (375 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading unsloth_zoo-2025.6.8-py3-none-any.whl (154 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.2/154.2 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xformers-0.0.30-cp311-cp311-manylinux_2_28_x86_64.whl (31.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m72.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.7.0-cp311-cp311-manylinux_2_28_x86_64.whl (865.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.3.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (156.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.6.4.1-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (393.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.6.80-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m133.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (897 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.5.1.17-py3-none-manylinux_2_28_x86_64.whl (571.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.0.4-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (200.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufile_cu12-1.11.1.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.7.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.1.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (158.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.4.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (216.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.3-py3-none-manylinux2014_x86_64.whl (156.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.26.2-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (201.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.85-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.6.77-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.22.0-cp311-cp311-manylinux_2_28_x86_64.whl (7.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m123.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.9.26-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.0/129.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
            "Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m127.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
            "Downloading msgspec-0.19.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (210 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, triton, sympy, shtab, protobuf, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, msgspec, fsspec, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, tyro, nvidia-cusolver-cu12, torch, datasets, xformers, torchvision, cut_cross_entropy, bitsandbytes, trl, unsloth_zoo, unsloth\n",
            "  Attempting uninstall: nvidia-cusparselt-cu12\n",
            "    Found existing installation: nvidia-cusparselt-cu12 0.6.2\n",
            "    Uninstalling nvidia-cusparselt-cu12-0.6.2:\n",
            "      Successfully uninstalled nvidia-cusparselt-cu12-0.6.2\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.4\n",
            "    Uninstalling datasets-2.14.4:\n",
            "      Successfully uninstalled datasets-2.14.4\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.71.2 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\n",
            "tensorflow-metadata 1.17.2 requires protobuf>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bitsandbytes-0.46.1 cut_cross_entropy-25.1.1 datasets-3.6.0 fsspec-2025.3.0 msgspec-0.19.0 nvidia-cublas-cu12-12.6.4.1 nvidia-cuda-cupti-cu12-12.6.80 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cuda-runtime-cu12-12.6.77 nvidia-cudnn-cu12-9.5.1.17 nvidia-cufft-cu12-11.3.0.4 nvidia-cufile-cu12-1.11.1.6 nvidia-curand-cu12-10.3.7.77 nvidia-cusolver-cu12-11.7.1.2 nvidia-cusparse-cu12-12.5.4.2 nvidia-cusparselt-cu12-0.6.3 nvidia-nccl-cu12-2.26.2 nvidia-nvjitlink-cu12-12.6.85 nvidia-nvtx-cu12-12.6.77 protobuf-3.20.3 shtab-1.7.2 sympy-1.14.0 torch-2.7.0 torchvision-0.22.0 triton-3.3.0 trl-0.19.0 tyro-0.9.26 unsloth-2025.6.12 unsloth_zoo-2025.6.8 xformers-0.0.30\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b7cf6302acf74de98df8c395bcc50d49"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from unsloth import FastLanguageModel\n",
        "\n",
        "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name=model_name,\n",
        "    max_seq_length=2048,\n",
        "    dtype=None,\n",
        "    load_in_4bit=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316,
          "referenced_widgets": [
            "8a4868541de24c2ab571ef9208f2ded3",
            "f2502722055f40e181a322f45ec97c5b",
            "2e21356defaa419a9bdcd00e12ce28fb",
            "1b5584f21de6448da72b2e4e0f629308",
            "68e389ad7bb648e5abb2607668c3e1ba",
            "d18d4532990447778860e176a5f300f9",
            "7f01d8a3e2c64c4bae6d04ccc27dfb1c",
            "774bc25cb2474b6d91c9bb1e333744fc",
            "0f7c29124e594f1999971f950730a37e",
            "e98759e710014e8493026c018305a82c",
            "b831854978b64e72ab142eeb21f04b3d",
            "a8f6a8d50ae34ddbbc2a8e4b1e57b390",
            "e8c7cdb006aa445dbaa89ed0e9e3dd8c",
            "c0b7cae5946a4efaab280334f8156e09",
            "82265314dc414406bb01aba60cbc146c",
            "52e8b5a9b6f749d29c18e3897ce0ba9e",
            "e7a77bc1d4ac47078c006c656f597211",
            "556a26633b7b4decb14d4aa64e60666b",
            "8f826be8c208412dbfe08e3822abd7a1",
            "d21bdc445fd7424cb42c5f94a3544884",
            "6b957562dc254e898d40a580dd55cbda",
            "a5efea9511684ca4bf0e69bdb37b9acd",
            "c9287998c4e149b6b4873dd59fcdc524",
            "73b362513ad843e6b159a90dfc5e2be6",
            "388ec9199ab049b2a20b4c542320a0f3",
            "d42cd20bafb54656b830d6fda2164cfc",
            "ff756fea9c63445bb104cc08e2228365",
            "3b7ba7fb3fe04561b473c1afb8d918e5",
            "acd9de881f194c69a8674a330b91c7b0",
            "6fe7f83921204c8298ca6afcca99aaf5",
            "b1912c81ff634e59ba0e06796d47f2bb",
            "31585124ac3b4d6e904c4b083195a7f0",
            "7d292ff20ec04de095509a8bfaffbad0",
            "c132260049d044b29bcfbd1e7f161acb",
            "fe697789de0149239d06cda4ecccbc46",
            "1601abe3c10145ecae8838bb72c96e67",
            "296792ff81f742e69a573f9ad5ba5f3a",
            "18b4b9e8628f47c5bcd884cac898dd3e",
            "f4bc00ba35a24209b0223fc555b3d1eb",
            "c96ce9068cb544d6b48ea5de8acf1888",
            "0ee7c186073740e59030a0e667b20b3b",
            "4fd4ae1b89df419092c09240326d6aea",
            "6fff2e203b434db39168e14bb2fc2070",
            "34a6feb9c03b4539ae1017f90c53100a",
            "2f68d76d59b84dfa93c2b25c134968e2",
            "529a3d041edf4887a40737bb632159c3",
            "1da9afdf6b284367be691a5c0c6a419d",
            "4f0c6f5a1509461385578177d3f01a18",
            "447a5476bb454c41b71e72b0b2c3c2f3",
            "2234c735e2f24d60b997fe365a429373",
            "12128bf5b6d44eea8de95d22dd8bbc4d",
            "25b5e47346fa4d4baf972f1961271795",
            "1cc8f0fc4ec247a3bf6eefb1f54354c0",
            "ae74afecd6c54baba4629930b76ae464",
            "0f52ddefc6534640b86d022eaa32ba60"
          ]
        },
        "id": "z3VPGMmRpkgz",
        "outputId": "8a0765f3-12fa-4702-f5c6-c1b2150a44d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
            "==((====))==  Unsloth 2025.6.12: Fast Llama patching. Transformers: 4.53.0.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/5.70G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a4868541de24c2ab571ef9208f2ded3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8f6a8d50ae34ddbbc2a8e4b1e57b390"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9287998c4e149b6b4873dd59fcdc524"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c132260049d044b29bcfbd1e7f161acb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/345 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f68d76d59b84dfa93c2b25c134968e2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0l9ZuxcOUIzE"
      },
      "outputs": [],
      "source": [
        "sample_data = {\n",
        "    \"Live_data_from_frontend\": \"\"\"User Info:\n",
        "user_name = Anika, email = anika@gmail.com, orders = 12, spent = 1543, email_verified = anika@gmail.com, refunds = 595, days_since_last = 228\n",
        "\n",
        "Product Info:\n",
        "product_name = Toe Ring, product_description = Simple metal toe rings in sterling silver or gold-plated finishes., product_color = Carmine, product_size = One Size, product_price = 706 INR, min_price_client = 367 INR, avg_inventory = 27, product_tag = spring, product_type = regular, images_count = 6, days_since_creation = 183\"\"\",\n",
        "    \"user\": \"User: 10% is less it seems is that all you can offer,ok lets say if you can make it to 25 thats a deal\",\n",
        "    \"response\": \"Bot: Id love to work something out how about 15% off, making it 600.1 INR? I'm open to hearing your offer too!\",\n",
        "    \"metadata\": {\n",
        "        \"user_email_id\": \"anika@gmail.com\",\n",
        "        \"user_score\": 21.55011282634933,\n",
        "        \"bargain_score\": 40,\n",
        "        \"product_price\": 706,\n",
        "        \"product_score\": 18.7020694468137,\n",
        "        \"admin_max_discount_from_min_price\": 48,\n",
        "        \"system_max_discount\": 24.0,\n",
        "        \"max_round_count\": 5,\n",
        "        \"current_round\": 2,\n",
        "        \"previous_round_discount_given\": 10,\n",
        "        \"user_req\": 25,\n",
        "        \"current_discount\": 15,\n",
        "        \"current_discount_price\": 600.1,\n",
        "        \"round_discounts\": {\n",
        "            \"round_count1\": 10,\n",
        "            \"round_count2\": 15,\n",
        "            \"round_count3\": 19,\n",
        "            \"round_count4\": 21,\n",
        "            \"round_count5\": 24\n",
        "        }\n",
        "    }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def parse_live_data(data_str):\n",
        "    try:\n",
        "        _, rest = data_str.split(\"User Info:\", 1)\n",
        "        user_part, product_part = rest.split(\"Product Info:\", 1)\n",
        "\n",
        "        def parse_section(section):\n",
        "            pattern = r\"(\\w+[\\s\\S]*?)\\s*=\\s*(.+?)(?=(?:,\\s*\\w+[\\s\\S]*?\\s*=)|$)\"\n",
        "            matches = re.findall(pattern, section.strip(), re.DOTALL)\n",
        "            return {k.strip(): v.strip() for k, v in matches}\n",
        "\n",
        "        return {\"user\": parse_section(user_part), \"product\": parse_section(product_part)}\n",
        "    except Exception as e:\n",
        "        return {\"user\": {}, \"product\": {}}\n",
        "\n",
        "# Run parser\n",
        "parsed = parse_live_data(sample_data[\"Live_data_from_frontend\"])\n",
        "\n",
        "# Print results\n",
        "print(\"User Data:\")\n",
        "for k, v in parsed[\"user\"].items():\n",
        "    print(f\"{k} = {v}\")\n",
        "\n",
        "print(\"\\nProduct Data:\")\n",
        "for k, v in parsed[\"product\"].items():\n",
        "    print(f\"{k} = {v}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WSULspMeH1s",
        "outputId": "9493a2b0-6c96-4897-f31d-72c3ba4c885b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "User Data:\n",
            "user_name = Anika\n",
            "email = anika@gmail.com\n",
            "orders = 12\n",
            "spent = 1543\n",
            "email_verified = anika@gmail.com\n",
            "refunds = 595\n",
            "days_since_last = 228\n",
            "\n",
            "Product Data:\n",
            "product_name = Toe Ring\n",
            "product_description = Simple metal toe rings in sterling silver or gold-plated finishes.\n",
            "product_color = Carmine\n",
            "product_size = One Size\n",
            "product_price = 706 INR\n",
            "min_price_client = 367 INR\n",
            "avg_inventory = 27\n",
            "product_tag = spring\n",
            "product_type = regular\n",
            "images_count = 6\n",
            "days_since_creation = 183\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_dict(d, parent_key='', sep='.'):\n",
        "    \"\"\"Flatten a nested dictionary for metadata.\"\"\"\n",
        "    items = {}\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.update(flatten_dict(v, new_key, sep=sep))\n",
        "        else:\n",
        "            items[new_key] = v\n",
        "    return items\n",
        "\n",
        "# Flatten the metadata\n",
        "flattened_metadata = flatten_dict(sample_data[\"metadata\"])\n",
        "\n",
        "# Print flattened metadata\n",
        "print(\"=== FLATTENED METADATA ===\")\n",
        "for key, value in flattened_metadata.items():\n",
        "    print(f\"{key} = {value}\")\n",
        "\n",
        "# Print conversation\n",
        "print(\"\\n=== CONVERSATION ===\")\n",
        "print(sample_data[\"user\"])\n",
        "print(sample_data[\"response\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fe0Z7p6Lfa3o",
        "outputId": "295916a6-0698-40ce-8cbc-9857319cbdfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FLATTENED METADATA ===\n",
            "user_email_id = anika@gmail.com\n",
            "user_score = 21.55011282634933\n",
            "bargain_score = 40\n",
            "product_price = 706\n",
            "product_score = 18.7020694468137\n",
            "admin_max_discount_from_min_price = 48\n",
            "system_max_discount = 24.0\n",
            "max_round_count = 5\n",
            "current_round = 2\n",
            "previous_round_discount_given = 10\n",
            "user_req = 25\n",
            "current_discount = 15\n",
            "current_discount_price = 600.1\n",
            "round_discounts.round_count1 = 10\n",
            "round_discounts.round_count2 = 15\n",
            "round_discounts.round_count3 = 19\n",
            "round_discounts.round_count4 = 21\n",
            "round_discounts.round_count5 = 24\n",
            "\n",
            "=== CONVERSATION ===\n",
            "User: 10% is less it seems is that all you can offer,ok lets say if you can make it to 25 thats a deal\n",
            "Bot: Id love to work something out how about 15% off, making it 600.1 INR? I'm open to hearing your offer too!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_cast(val, to_type, default):\n",
        "    \"\"\"Safely cast a value to a type, returning default if it fails.\"\"\"\n",
        "    try:\n",
        "        return to_type(val)\n",
        "    except (ValueError, TypeError):\n",
        "        return default\n",
        "\n",
        "\n",
        "\n",
        "def build_context(entry):\n",
        "    \"\"\"Build a flat context dict from a single entry in final_output.json, using all parameters.\"\"\"\n",
        "    live_data_str = entry.get(\"Live_data_from_frontend\", \"\")\n",
        "    parsed = parse_live_data(live_data_str)\n",
        "    user_info = parsed.get(\"user\", {})\n",
        "    product_info = parsed.get(\"product\", {})\n",
        "    metadata = entry.get(\"metadata\", {})  # Don't flatten metadata yet\n",
        "\n",
        "    # Extract round_discounts before flattening\n",
        "    round_discounts = metadata.get(\"round_discounts\", {})\n",
        "\n",
        "    # Now flatten the rest of metadata\n",
        "    flattened_metadata = flatten_dict(metadata)\n",
        "\n",
        "    # Build context with all possible parameters\n",
        "    context = {}\n",
        "\n",
        "    # Add all user/product info\n",
        "    for k, v in user_info.items():\n",
        "        context[f\"user_{k}\"] = v\n",
        "    for k, v in product_info.items():\n",
        "        context[f\"product_{k}\"] = v\n",
        "\n",
        "    # Add all metadata (flattened)\n",
        "    for k, v in flattened_metadata.items():\n",
        "        if k != 'round_discounts':  # Skip round_discounts as it's handled separately\n",
        "            context[f\"meta_{k}\"] = v\n",
        "\n",
        "    # Add round_discounts directly to context\n",
        "    context[\"round_discounts\"] = round_discounts\n",
        "\n",
        "    # Rest of your build_context function remains the same...\n",
        "    context[\"user_input\"] = entry.get(\"user\", \"\").replace(\"User: \", \"\").strip()\n",
        "    context[\"gold_response\"] = entry.get(\"response\", \"\").replace(\"Bot: \", \"\").strip()\n",
        "\n",
        "    # Some fields for prompt logic (with safe casting)\n",
        "    context[\"orders\"] = safe_cast(user_info.get(\"orders\", 0), int, 0)\n",
        "    context[\"spent\"] = safe_cast(user_info.get(\"spent\", 0), int, 0)\n",
        "    context[\"refunds\"] = safe_cast(user_info.get(\"refunds\", 0), int, 0)\n",
        "    context[\"days_since_last\"] = safe_cast(user_info.get(\"days_since_last\", 0), int, 0)\n",
        "    context[\"email_verified\"] = str(user_info.get(\"email_verified\", \"False\")).lower() in (\"true\", \"1\", \"yes\")\n",
        "\n",
        "    context[\"product_name\"] = product_info.get(\"product_name\", \"Unknown Product\")\n",
        "    context[\"product_description\"] = product_info.get(\"product_description\", \"\")\n",
        "    context[\"product_price\"] = safe_cast(str(product_info.get(\"product_price\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"min_price_client\"] = safe_cast(str(product_info.get(\"min_price_client\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"avg_inventory\"] = safe_cast(product_info.get(\"avg_inventory\", 0), int, 0)\n",
        "    context[\"product_tag\"] = product_info.get(\"product_tag\", \"\")\n",
        "    context[\"product_type\"] = product_info.get(\"product_type\", \"\")\n",
        "    context[\"images_count\"] = safe_cast(product_info.get(\"images_count\", 0), int, 0)\n",
        "    context[\"days_since_creation\"] = safe_cast(product_info.get(\"days_since_creation\", 0), int, 0)\n",
        "\n",
        "    # Metadata fields for prompt logic (with safe casting)\n",
        "    context[\"user_score\"] = safe_cast(metadata.get(\"user_score\", 0), float, 0)\n",
        "    context[\"bargain_score\"] = safe_cast(metadata.get(\"bargain_score\", 0), float, 0)\n",
        "    context[\"product_score\"] = safe_cast(metadata.get(\"product_score\", 0), float, 0)\n",
        "    context[\"admin_max_discount_from_min_price\"] = safe_cast(metadata.get(\"admin_max_discount_from_min_price\", 0), float, 0)\n",
        "    context[\"system_max_discount\"] = safe_cast(metadata.get(\"system_max_discount\", 0), float, 0)\n",
        "    context[\"max_round_count\"] = safe_cast(metadata.get(\"max_round_count\", 0), int, 0)\n",
        "    context[\"current_round\"] = safe_cast(metadata.get(\"current_round\", 0), int, 0)\n",
        "    context[\"previous_round_discount_given\"] = safe_cast(metadata.get(\"previous_round_discount_given\", 0), float, 0)\n",
        "    context[\"user_req\"] = safe_cast(metadata.get(\"user_req\", 0), float, 0)\n",
        "    context[\"current_discount\"] = safe_cast(metadata.get(\"current_discount\", 0), float, 0)\n",
        "    context[\"current_discount_price\"] = safe_cast(metadata.get(\"current_discount_price\", 0), float, 0)\n",
        "\n",
        "    return context\n",
        "\n",
        "# Build and print the context\n",
        "context = build_context(sample_data)\n",
        "print(\"=== CONTEXT DICTIONARY ===\")\n",
        "for key, value in context.items():\n",
        "    if key == 'round_discounts':\n",
        "        print(\"\\nRound Discounts:\")\n",
        "        for rd_key, rd_value in sorted(value.items()):\n",
        "            print(f\"  {rd_key}: {rd_value}%\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5NYDSyKgHCr",
        "outputId": "c6e3afa4-33fd-4c7d-d33d-d280a5c0653e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CONTEXT DICTIONARY ===\n",
            "user_user_name: Anika\n",
            "user_email: anika@gmail.com\n",
            "user_orders: 12\n",
            "user_spent: 1543\n",
            "user_email_verified: anika@gmail.com\n",
            "user_refunds: 595\n",
            "user_days_since_last: 228\n",
            "product_product_name: Toe Ring\n",
            "product_product_description: Simple metal toe rings in sterling silver or gold-plated finishes.\n",
            "product_product_color: Carmine\n",
            "product_product_size: One Size\n",
            "product_product_price: 706 INR\n",
            "product_min_price_client: 367 INR\n",
            "product_avg_inventory: 27\n",
            "product_product_tag: spring\n",
            "product_product_type: regular\n",
            "product_images_count: 6\n",
            "product_days_since_creation: 183\n",
            "meta_user_email_id: anika@gmail.com\n",
            "meta_user_score: 21.55011282634933\n",
            "meta_bargain_score: 40\n",
            "meta_product_price: 706\n",
            "meta_product_score: 18.7020694468137\n",
            "meta_admin_max_discount_from_min_price: 48\n",
            "meta_system_max_discount: 24.0\n",
            "meta_max_round_count: 5\n",
            "meta_current_round: 2\n",
            "meta_previous_round_discount_given: 10\n",
            "meta_user_req: 25\n",
            "meta_current_discount: 15\n",
            "meta_current_discount_price: 600.1\n",
            "meta_round_discounts.round_count1: 10\n",
            "meta_round_discounts.round_count2: 15\n",
            "meta_round_discounts.round_count3: 19\n",
            "meta_round_discounts.round_count4: 21\n",
            "meta_round_discounts.round_count5: 24\n",
            "\n",
            "Round Discounts:\n",
            "  round_count1: 10%\n",
            "  round_count2: 15%\n",
            "  round_count3: 19%\n",
            "  round_count4: 21%\n",
            "  round_count5: 24%\n",
            "user_input: 10% is less it seems is that all you can offer,ok lets say if you can make it to 25 thats a deal\n",
            "gold_response: Id love to work something out how about 15% off, making it 600.1 INR? I'm open to hearing your offer too!\n",
            "orders: 12\n",
            "spent: 1543\n",
            "refunds: 595\n",
            "days_since_last: 228\n",
            "email_verified: False\n",
            "product_name: Toe Ring\n",
            "product_description: Simple metal toe rings in sterling silver or gold-plated finishes.\n",
            "product_price: 706\n",
            "min_price_client: 367\n",
            "avg_inventory: 27\n",
            "product_tag: spring\n",
            "product_type: regular\n",
            "images_count: 6\n",
            "days_since_creation: 183\n",
            "user_score: 21.55011282634933\n",
            "bargain_score: 40.0\n",
            "product_score: 18.7020694468137\n",
            "admin_max_discount_from_min_price: 48.0\n",
            "system_max_discount: 24.0\n",
            "max_round_count: 5\n",
            "current_round: 2\n",
            "previous_round_discount_given: 10.0\n",
            "user_req: 25.0\n",
            "current_discount: 15.0\n",
            "current_discount_price: 600.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import TextGenerationPipeline\n",
        "\n",
        "pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer, framework=\"pt\")\n",
        "\n",
        "def parse_live_data(data_str):\n",
        "    \"\"\"Parse the Live_data_from_frontend string into user and product dicts.\"\"\"\n",
        "    try:\n",
        "        _, rest = data_str.split(\"User Info:\", 1)\n",
        "        user_part, product_part = rest.split(\"Product Info:\", 1)\n",
        "        def parse_section(section):\n",
        "            pattern = r\"(\\w+[\\s\\S]*?)\\s*=\\s*(.+?)(?=(?:,\\s*\\w+[\\s\\S]*?\\s*=)|$)\"\n",
        "            matches = re.findall(pattern, section.strip(), re.DOTALL)\n",
        "            return {k.strip(): v.strip() for k, v in matches}\n",
        "        return {\"user\": parse_section(user_part), \"product\": parse_section(product_part)}\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to parse Live_data_from_frontend: {e}\")\n",
        "        return {\"user\": {}, \"product\": {}}\n",
        "\n",
        "def flatten_dict(d, parent_key='', sep='.'):\n",
        "    \"\"\"Flatten a nested dictionary for metadata.\"\"\"\n",
        "    items = {}\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.update(flatten_dict(v, new_key, sep=sep))\n",
        "        else:\n",
        "            items[new_key] = v\n",
        "    return items\n",
        "\n",
        "def safe_cast(val, to_type, default):\n",
        "    try:\n",
        "        return to_type(val)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def build_context(entry):\n",
        "    \"\"\"Build a flat context dict from a single entry in final_output.json, using all parameters.\"\"\"\n",
        "    live_data_str = entry.get(\"Live_data_from_frontend\", \"\")\n",
        "    parsed = parse_live_data(live_data_str)\n",
        "    user_info = parsed.get(\"user\", {})\n",
        "    product_info = parsed.get(\"product\", {})\n",
        "    metadata = flatten_dict(entry.get(\"metadata\", {}))\n",
        "\n",
        "    # Build context with all possible parameters\n",
        "    context = {}\n",
        "\n",
        "    # Add all user/product info\n",
        "    for k, v in user_info.items():\n",
        "        context[f\"user_{k}\"] = v\n",
        "    for k, v in product_info.items():\n",
        "        context[f\"product_{k}\"] = v\n",
        "\n",
        "    # Add all metadata (flattened)\n",
        "    for k, v in metadata.items():\n",
        "        context[f\"meta_{k}\"] = v\n",
        "\n",
        "    # Add top-level fields\n",
        "    context[\"user_input\"] = entry.get(\"user\", \"\").replace(\"User: \", \"\").strip()\n",
        "    context[\"gold_response\"] = entry.get(\"response\", \"\").replace(\"Bot: \", \"\").strip()\n",
        "\n",
        "    # Some fields for prompt logic (with safe casting)\n",
        "    context[\"orders\"] = safe_cast(user_info.get(\"orders\", 0), int, 0)\n",
        "    context[\"spent\"] = safe_cast(user_info.get(\"spent\", 0), int, 0)\n",
        "    context[\"refunds\"] = safe_cast(user_info.get(\"refunds\", 0), int, 0)\n",
        "    context[\"days_since_last\"] = safe_cast(user_info.get(\"days_since_last\", 0), int, 0)\n",
        "    context[\"email_verified\"] = str(user_info.get(\"email_verified\", \"False\")).lower() in (\"true\", \"1\", \"yes\")\n",
        "\n",
        "    context[\"product_name\"] = product_info.get(\"product_name\", \"Unknown Product\")\n",
        "    context[\"product_description\"] = product_info.get(\"product_description\", \"\")\n",
        "    context[\"product_price\"] = safe_cast(str(product_info.get(\"product_price\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"min_price_client\"] = safe_cast(str(product_info.get(\"min_price_client\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"avg_inventory\"] = safe_cast(product_info.get(\"avg_inventory\", 0), int, 0)\n",
        "    context[\"product_tag\"] = product_info.get(\"product_tag\", \"\")\n",
        "    context[\"product_type\"] = product_info.get(\"product_type\", \"\")\n",
        "    context[\"images_count\"] = safe_cast(product_info.get(\"images_count\", 0), int, 0)\n",
        "    context[\"days_since_creation\"] = safe_cast(product_info.get(\"days_since_creation\", 0), int, 0)\n",
        "\n",
        "    # Metadata fields for prompt logic (with safe casting)\n",
        "    context[\"user_score\"] = safe_cast(metadata.get(\"user_score\", 0), float, 0)\n",
        "    context[\"bargain_score\"] = safe_cast(metadata.get(\"bargain_score\", 0), float, 0)\n",
        "    context[\"product_score\"] = safe_cast(metadata.get(\"product_score\", 0), float, 0)\n",
        "    context[\"admin_max_discount_from_min_price\"] = safe_cast(metadata.get(\"admin_max_discount_from_min_price\", 0), float, 0)\n",
        "    context[\"system_max_discount\"] = safe_cast(metadata.get(\"system_max_discount\", 0), float, 0)\n",
        "    context[\"max_round_count\"] = safe_cast(metadata.get(\"max_round_count\", 0), int, 0)\n",
        "    context[\"current_round\"] = safe_cast(metadata.get(\"current_round\", 0), int, 0)\n",
        "    context[\"previous_round_discount_given\"] = safe_cast(metadata.get(\"previous_round_discount_given\", 0), float, 0)\n",
        "    context[\"user_req\"] = safe_cast(metadata.get(\"user_req\", 0), float, 0)\n",
        "    context[\"current_discount\"] = safe_cast(metadata.get(\"current_discount\", 0), float, 0)\n",
        "    context[\"current_discount_price\"] = safe_cast(metadata.get(\"current_discount_price\", 0), float, 0)\n",
        "    context[\"round_discounts\"] = metadata.get(\"round_discounts\", {})\n",
        "\n",
        "    return context\n",
        "\n",
        "def get_messages(context):\n",
        "    # Parameter influence summary (as in your prompt)\n",
        "    parameter_summary = f\"\"\"\n",
        "Parameter: Orders → More orders → Higher discount → {context['orders']}\n",
        "Parameter: Total Spent → More money spent → Higher discount → ₹{context['spent']}\n",
        "Parameter: Days Since Last Purchase → Longer time since last purchase → Higher discount → {context['days_since_last']} days\n",
        "Parameter: Inventory Level → More inventory → Higher discount → {context['avg_inventory']} units\n",
        "Parameter: Days Since Creation → Older product → Higher discount → {context['days_since_creation']} days\n",
        "Parameter: Image Count → More images → Higher discount → {context['images_count']}\n",
        "Parameter: Bargain Score → Higher score → Higher discount → {context['bargain_score']}\n",
        "Parameter: Max Round Count → More rounds available → Can afford higher discount later → {context['max_round_count']}\n",
        "\n",
        "Parameter: Refunds → More refunds → Lower discount → ₹{context['refunds']}\n",
        "Parameter: Current Round → Later rounds can go less high → Higher round number → Lower discount allowed → Round {context['current_round']}\n",
        "Parameter: Product Price → Higher price → Lower discount allowed → ₹{context['product_price']}\n",
        "Parameter: Min Price Client → Higher minimum → Less room for discount → ₹{context['min_price_client']}\n",
        "Parameter: System Max Discount → Lower max → Lower discount allowed → {context['system_max_discount']}%\n",
        "\"\"\"\n",
        "\n",
        "    user_prompt = f\"\"\"\n",
        "{parameter_summary}\n",
        "\n",
        "User Profile:\n",
        "- Orders: {context['orders']}\n",
        "- Total Spent: ₹{context['spent']}\n",
        "- Refunds: ₹{context['refunds']}\n",
        "- Days Since Last Purchase: {context['days_since_last']}\n",
        "- Email Verified: {\"Yes\" if context['email_verified'] else \"No\"}\n",
        "\n",
        "Product Details:\n",
        "- Inventory Level: {context['avg_inventory']} units\n",
        "- Age: {context['days_since_creation']} days old\n",
        "- Image Count: {context['images_count']}\n",
        "- Tag: {context['product_tag']}\n",
        "- Type: {context['product_type']}\n",
        "\n",
        "Negotiation Info:\n",
        "- You're on Round {context['current_round']} of {context['max_round_count']}\n",
        "- Maximum Allowed Discount: {context['system_max_discount']}%\n",
        "- Last Offer: {context['previous_round_discount_given']}%\n",
        "- Customer wants more than the last offer\n",
        "\n",
        "The customer said: \"{context['user_input']}\"\n",
        "\n",
        "Based on this, suggest a new discount for this round only.\n",
        "Don't jump straight to the maximum — save room for future rounds.\n",
        "\n",
        "Respond with only one persuasive line that includes:\n",
        "- The discount percentage\n",
        "- The final price after discount\n",
        "\"\"\"\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "You are an intelligent shopping assistant negotiating prices over multiple rounds.\n",
        "Your goal is to reach a deal while strategically managing discounts across all rounds.\n",
        "\n",
        "Rules:\n",
        "1. You're currently in Round {context['current_round']} of {context['max_round_count']}.\n",
        "2. Your maximum allowed discount is {context['system_max_discount']}%.\n",
        "3. Don't jump straight to the highest discount — leave room for future rounds.\n",
        "4. Suggest a reasonable increase from the last offer: {context['previous_round_discount_given']}%.\n",
        "5. Always include: discount %, final price, optional negotiation invite.\n",
        "6. Respond with only one persuasive line — no extra text or explanation.\n",
        "7. And discount should always be less or equal to {context['system_max_discount']}%\n",
        "\"\"\"\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
        "        {\"role\": \"user\", \"content\": user_prompt.strip()}\n",
        "    ]\n",
        "\n",
        "def extract_discount(text):\n",
        "    \"\"\"Extract the discount percentage from the model's response (best effort).\"\"\"\n",
        "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*%', text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    return None\n",
        "\n",
        "def generate_responses(input_file_path, output_file_path, limit=50):\n",
        "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        input_data = json.load(f)\n",
        "    results = []\n",
        "    for idx, entry in enumerate(input_data[:limit]):\n",
        "        print(f\"Processing scenario {idx + 1}/{limit}\")\n",
        "        context = build_context(entry)\n",
        "        messages = get_messages(context)\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "        outputs = pipeline(\n",
        "            prompt,\n",
        "            max_new_tokens=100,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "        bot_response = outputs[0][\"generated_text\"][len(prompt):].strip()\n",
        "        discount_pred = extract_discount(bot_response)\n",
        "        # Append predicted discount to response\n",
        "        full_bot_response = f\"Bot: {bot_response}\"\n",
        "        if discount_pred is not None:\n",
        "            full_bot_response += f\" [Predicted Discount: {discount_pred}%]\"\n",
        "        # Copy original entry, update response and gold\n",
        "        updated_entry = entry.copy()\n",
        "        updated_entry[\"gold\"] = entry.get(\"response\", \"\")     # Original Bot response\n",
        "        updated_entry[\"response\"] = full_bot_response         # New model-generated response\n",
        "        results.append(updated_entry)\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"✅ Saved {len(results)} responses to {output_file_path}\")\n",
        "\n",
        "# Example usage (uncomment to run):\n",
        "generate_responses(\"final_output.json\", \"responses.json\", limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ndm2mcdrj8Cd",
        "outputId": "e11ca3b9-6b6e-42ee-91dc-c602d16191a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing scenario 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "LlamaForCausalLM has no `_prepare_4d_causal_attention_mask_with_cache_position` method defined in its base modeling class. Compiled forward passes will be sub-optimal. If you're writing code, see Llama for an example implementation. If you're a user, please report this issue on GitHub.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing scenario 2/10\n",
            "Processing scenario 3/10\n",
            "Processing scenario 4/10\n",
            "Processing scenario 5/10\n",
            "Processing scenario 6/10\n",
            "Processing scenario 7/10\n",
            "Processing scenario 8/10\n",
            "Processing scenario 9/10\n",
            "Processing scenario 10/10\n",
            "✅ Saved 10 responses to responses.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextGenerationPipeline\n",
        "import json\n",
        "\n",
        "def generate_discount_prompt(context):\n",
        "    # Calculate derived values\n",
        "    min_price_pct = (context['min_price'] / context['product_price']) * 100\n",
        "    refund_rate = (context['refunds'] / context['total_spent']) * 100 if context['total_spent'] > 0 else 0\n",
        "    current_price = context['product_price'] * (1 - context['current_discount']/100)\n",
        "    next_round = min(context['current_round'] + 1, context['max_rounds'])\n",
        "\n",
        "    return f\"\"\"**DISCOUNT CALCULATION FRAMEWORK**\n",
        "\n",
        "**1. SCENARIO ANALYSIS**\n",
        "\n",
        "**User Profile:**\n",
        "- **Orders**: {context['orders']} ({'New' if context['orders'] < 5 else 'Medium' if context['orders'] < 20 else 'Loyal'})\n",
        "- **Total Spent**: ₹{context['total_spent']:,} ({'Low' if context['total_spent'] < 1000 else 'Medium' if context['total_spent'] < 5000 else 'High'})\n",
        "- **Refund Rate**: {refund_rate:.1f}% ({'Low' if refund_rate < 10 else 'Medium' if refund_rate < 25 else 'High'} risk)\n",
        "- **Last Active**: {context['days_since_last']} days ({'Recent' if context['days_since_last'] < 30 else 'Average' if context['days_since_last'] < 90 else 'Inactive'})\n",
        "- **Bargain Skill**: {context['bargain_score']}/100 ({'Weak' if context['bargain_score'] < 40 else 'Average' if context['bargain_score'] < 70 else 'Strong'})\n",
        "\n",
        "**Product Status:**\n",
        "- **Price**: ₹{context['product_price']}\n",
        "- **Min Price**: ₹{context['min_price']} ({min_price_pct:.0f}% of original)\n",
        "- **Inventory**: {context['inventory']} units ({'Critical' if context['inventory'] < 5 else 'Low' if context['inventory'] < 20 else 'Normal'})\n",
        "- **Age**: {context['product_age']} days ({'New' if context['product_age'] < 30 else 'Average' if context['product_age'] < 180 else 'Old'})\n",
        "- **Type**: {context['product_type']}\n",
        "- **Tag**: {context['product_tag']}\n",
        "\n",
        "**Negotiation State:**\n",
        "- **Round**: {context['current_round']}/{context['max_rounds']}\n",
        "- **Previous Discount**: {context['prev_discount']}%\n",
        "- **Current Offer**: {context['current_discount']}% (₹{current_price:.2f})\n",
        "- **User's Ask**: {context['user_ask']}%\n",
        "- **System Max**: {context['system_max_discount']}%\n",
        "\n",
        "**2. DECISION FACTORS**\n",
        "\n",
        "**A. User Value (Score: {context['user_score']:.1f}/45)**\n",
        "- Tier: {'Low' if context['user_score'] < 16 else 'Medium' if context['user_score'] < 31 else 'High'}\n",
        "- Adjustment: {0.5 if context['user_score'] < 16 else 1 if context['user_score'] < 31 else 1.5}-{1 if context['user_score'] < 16 else 1.5 if context['user_score'] < 31 else 2}%\n",
        "\n",
        "**B. Inventory Status**\n",
        "- Level: {'Critical' if context['inventory'] < 5 else 'Low' if context['inventory'] < 20 else 'Normal'}\n",
        "- Adjustment: {2 if context['inventory'] < 5 else 1 if context['inventory'] < 20 else 0.5}-{3 if context['inventory'] < 5 else 2 if context['inventory'] < 20 else 1}%\n",
        "\n",
        "**C. Product Age**\n",
        "- Category: {'New' if context['product_age'] < 30 else 'Average' if context['product_age'] < 180 else 'Old'}\n",
        "- Adjustment: {0 if context['product_age'] < 30 else 0.5 if context['product_age'] < 180 else 1}-{0.5 if context['product_age'] < 30 else 1 if context['product_age'] < 180 else 2}%\n",
        "\n",
        "**D. Bargain Score**\n",
        "- Level: {'Weak' if context['bargain_score'] < 40 else 'Average' if context['bargain_score'] < 70 else 'Strong'}\n",
        "- Adjustment: {0 if context['bargain_score'] < 40 else 0.5 if context['bargain_score'] < 70 else 1}-{1 if context['bargain_score'] < 40 else 1.5 if context['bargain_score'] < 70 else 2}%\n",
        "\n",
        "**E. Round Progression**\n",
        "- Phase: {'Early' if context['current_round'] <= 2 else 'Middle' if context['current_round'] <= 4 else 'Final'}\n",
        "- Expected Increase: {2 if context['current_round'] <= 2 else 1 if context['current_round'] <= 4 else 0.5}-{3 if context['current_round'] <= 2 else 2 if context['current_round'] <= 4 else 1}%\n",
        "\n",
        "**3. DISCOUNT CALCULATION**\n",
        "\n",
        "**Current Round ({context['current_round']}/{context['max_rounds']}):**\n",
        "- Base: {context['prev_discount']}%\n",
        "- New Offer: {context['current_discount']}%\n",
        "- Price: ₹{current_price:.2f}\n",
        "\n",
        "**Future Rounds:**\n",
        "1. Calculate discount for each remaining round\n",
        "2. Ensure progression is logical (increasing discounts)\n",
        "3. Final round should approach system max discount\n",
        "4. All prices must be ≥ ₹{context['min_price']}\n",
        "\n",
        "**4. OUTPUT FORMAT**\n",
        "{{\n",
        "  \"discount_progression\": {{\n",
        "    \"round_{context['current_round']}\": \"{context['current_discount']}% (₹{current_price:.2f})\",\n",
        "    \"round_{context['current_round'] + 1}\": \"X% (₹Y)\",\n",
        "    \"round_{context['current_round'] + 2}\": \"Z% (₹W)\",\n",
        "    ... (for all remaining rounds)\n",
        "    \"round_{context['max_rounds']}\": \"{context['system_max_discount']}% (₹{context['product_price'] * (1 - context['system_max_discount']/100):.2f})\"\n",
        "  }},\n",
        "  \"reasoning\": \"Explanation of discount progression logic\",\n",
        "  \"constraints\": {{\n",
        "    \"min_price\": {context['min_price']},\n",
        "    \"system_max\": {context['system_max_discount']}%,\n",
        "    \"current_round\": {context['current_round']}/{context['max_rounds']}\n",
        "  }}\n",
        "}}\n",
        "\n",
        "**5. EXAMPLE RESPONSE**\n",
        "{{\n",
        "  \"discount_progression\": {{\n",
        "    \"round_3\": \"11% (₹581.17)\",\n",
        "    \"round_4\": \"12% (₹574.64)\",\n",
        "    \"round_5\": \"13.5% (₹564.85)\",\n",
        "    \"round_6\": \"15% (₹555.05)\"\n",
        "  }},\n",
        "  \"reasoning\": \"Gradual increase based on inventory status (critical) and user value (high). Final round reaches system max discount.\",\n",
        "  \"constraints\": {{\n",
        "    \"min_price\": 496,\n",
        "    \"system_max\": 15%,\n",
        "    \"current_round\": \"3/6\"\n",
        "  }}\n",
        "}}\"\"\"\n",
        "\n",
        "def calculate_discount_progression(context):\n",
        "    \"\"\"Calculate a logical discount progression from current round to max round\"\"\"\n",
        "    progression = {}\n",
        "\n",
        "    # Add current round\n",
        "    current_price = context['product_price'] * (1 - context['current_discount']/100)\n",
        "    progression[f\"round_{context['current_round']}\"] = f\"{context['current_discount']}% (₹{current_price:.2f})\"\n",
        "\n",
        "    # Calculate remaining rounds\n",
        "    remaining_rounds = context['max_rounds'] - context['current_round']\n",
        "    if remaining_rounds <= 0:\n",
        "        return progression\n",
        "\n",
        "    # Calculate discount increment per round\n",
        "    discount_gap = context['system_max_discount'] - context['current_discount']\n",
        "\n",
        "    # Determine if we should use linear or non-linear progression\n",
        "    if context['inventory'] < 5 or context['user_score'] > 30:\n",
        "        # For critical inventory or high-value users, front-load discounts\n",
        "        increments = []\n",
        "        for i in range(remaining_rounds):\n",
        "            if i == remaining_rounds - 1:  # Last round\n",
        "                increments.append(discount_gap - sum(increments))\n",
        "            else:\n",
        "                # Front-loaded progression\n",
        "                round_increment = discount_gap * (0.4 - 0.05 * i) / (remaining_rounds - 1)\n",
        "                increments.append(round_increment)\n",
        "    else:\n",
        "        # Linear progression for normal cases\n",
        "        increment_per_round = discount_gap / remaining_rounds\n",
        "        increments = [increment_per_round] * remaining_rounds\n",
        "\n",
        "    # Apply increments to calculate future discounts\n",
        "    current_discount = context['current_discount']\n",
        "    for i in range(remaining_rounds):\n",
        "        round_num = context['current_round'] + i + 1\n",
        "        current_discount += increments[i]\n",
        "        # Round to nearest 0.5\n",
        "        rounded_discount = round(current_discount * 2) / 2\n",
        "        # Ensure we don't exceed system max\n",
        "        rounded_discount = min(rounded_discount, context['system_max_discount'])\n",
        "\n",
        "        price = context['product_price'] * (1 - rounded_discount/100)\n",
        "        progression[f\"round_{round_num}\"] = f\"{rounded_discount}% (₹{price:.2f})\"\n",
        "\n",
        "    return progression\n",
        "\n",
        "def generate_discount_response(context, model, tokenizer):\n",
        "    # Generate the prompt using the context\n",
        "    prompt = generate_discount_prompt(context)\n",
        "\n",
        "    # Format the messages for the chat template\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful pricing assistant that determines optimal discount offers.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    # Apply chat template\n",
        "    formatted_prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "\n",
        "    # Initialize the pipeline\n",
        "    pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer, framework=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    outputs = pipeline(\n",
        "        formatted_prompt,\n",
        "        max_new_tokens=300,  # Increased for detailed responses\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id,\n",
        "    )\n",
        "\n",
        "    # Extract just the assistant's response\n",
        "    bot_response = outputs[0][\"generated_text\"][len(formatted_prompt):].strip()\n",
        "\n",
        "    # Extract JSON from response\n",
        "    json_start = bot_response.find('{')\n",
        "    json_end = bot_response.rfind('}') + 1\n",
        "\n",
        "    if json_start >= 0 and json_end > 0:\n",
        "        try:\n",
        "            parsed = json.loads(bot_response[json_start:json_end])\n",
        "\n",
        "            # Ensure we have a complete discount progression\n",
        "            if 'discount_progression' in parsed:\n",
        "                # Check if all rounds are included\n",
        "                has_all_rounds = True\n",
        "                for r in range(context['current_round'], context['max_rounds'] + 1):\n",
        "                    if f\"round_{r}\" not in parsed['discount_progression']:\n",
        "                        has_all_rounds = False\n",
        "                        break\n",
        "\n",
        "                if has_all_rounds:\n",
        "                    return parsed\n",
        "\n",
        "            # If we don't have a complete progression, fall back to calculated one\n",
        "            parsed['discount_progression'] = calculate_discount_progression(context)\n",
        "            return parsed\n",
        "\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # If JSON parsing fails, create a fallback response\n",
        "    progression = calculate_discount_progression(context)\n",
        "\n",
        "    # Extract next round discount for convenience\n",
        "    next_round = context['current_round'] + 1\n",
        "    next_discount = None\n",
        "    if f\"round_{next_round}\" in progression:\n",
        "        discount_text = progression[f\"round_{next_round}\"]\n",
        "        next_discount = float(discount_text.split('%')[0])\n",
        "\n",
        "    return {\n",
        "        \"discount_progression\": progression,\n",
        "        \"reasoning\": \"Calculated discount progression based on user value, inventory status, and round progression.\",\n",
        "        \"constraints\": {\n",
        "            \"min_price\": context['min_price'],\n",
        "            \"system_max\": context['system_max_discount'],\n",
        "            \"current_round\": f\"{context['current_round']}/{context['max_rounds']}\"\n",
        "        }\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Example context\n",
        "\n",
        "    example_context = {\n",
        "    # User\n",
        "    'orders': 12,\n",
        "    'total_spent': 1543,\n",
        "    'refunds': 595,\n",
        "    'days_since_last': 228,\n",
        "    'bargain_score': 40,\n",
        "    'user_score': 21.55,\n",
        "\n",
        "    # Product\n",
        "    'product_price': 706,\n",
        "    'min_price': 367,\n",
        "    'inventory': 27,\n",
        "    'product_age': 183,\n",
        "    'product_type': 'regular',\n",
        "    'product_tag': 'spring',\n",
        "\n",
        "    # Negotiation\n",
        "    'current_round': 2,\n",
        "    'max_rounds': 5,\n",
        "    'prev_discount': 10,\n",
        "    'current_discount': 18,\n",
        "    'user_ask': 25,\n",
        "    'system_max_discount': 24.0\n",
        "    }\n",
        "\n",
        "    # Generate discount response\n",
        "    response = generate_discount_response(example_context, model, tokenizer)\n",
        "\n",
        "    # Print the discount information\n",
        "    print(f\"Current Round: {example_context['current_round']}/{example_context['max_rounds']}\")\n",
        "    print(f\"Current Discount: {example_context['current_discount']}%\")\n",
        "    print(f\"Current Price: ₹{example_context['product_price'] * (1 - example_context['current_discount']/100):.2f}\")\n",
        "\n",
        "    # Print discount progression\n",
        "    print(\"\\nDiscount Progression:\")\n",
        "    for round_key, round_value in response.get('discount_progression', {}).items():\n",
        "        print(f\"{round_key}: {round_value}\")\n",
        "\n",
        "    print(f\"\\nReasoning: {response.get('reasoning')}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zfc2yd24fQpe",
        "outputId": "1785db54-1923-4d1c-82bc-c60bd3d1a3c1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Round: 2/5\n",
            "Current Discount: 18%\n",
            "Current Price: ₹578.92\n",
            "\n",
            "Discount Progression:\n",
            "round_2: 18% (₹578.92)\n",
            "round_3: 20.0% (₹564.80)\n",
            "round_4: 22.0% (₹550.68)\n",
            "round_5: 24.0% (₹536.56)\n",
            "\n",
            "Reasoning: Calculated discount progression based on user value, inventory status, and round progression.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NEW PROMPT TEMPLATE 1"
      ],
      "metadata": {
        "id": "sjySkj5f2Wb5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "from transformers import TextGenerationPipeline\n",
        "\n",
        "pipeline = TextGenerationPipeline(model=model, tokenizer=tokenizer, framework=\"pt\")\n",
        "\n",
        "def parse_live_data(data_str):\n",
        "    \"\"\"Parse the Live_data_from_frontend string into user and product dicts.\"\"\"\n",
        "    try:\n",
        "        _, rest = data_str.split(\"User Info:\", 1)\n",
        "        user_part, product_part = rest.split(\"Product Info:\", 1)\n",
        "        def parse_section(section):\n",
        "            pattern = r\"(\\w+[\\s\\S]*?)\\s*=\\s*(.+?)(?=(?:,\\s*\\w+[\\s\\S]*?\\s*=)|$)\"\n",
        "            matches = re.findall(pattern, section.strip(), re.DOTALL)\n",
        "            return {k.strip(): v.strip() for k, v in matches}\n",
        "        return {\"user\": parse_section(user_part), \"product\": parse_section(product_part)}\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] Failed to parse Live_data_from_frontend: {e}\")\n",
        "        return {\"user\": {}, \"product\": {}}\n",
        "\n",
        "def flatten_dict(d, parent_key='', sep='.'):\n",
        "    \"\"\"Flatten a nested dictionary for metadata.\"\"\"\n",
        "    items = {}\n",
        "    for k, v in d.items():\n",
        "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
        "        if isinstance(v, dict):\n",
        "            items.update(flatten_dict(v, new_key, sep=sep))\n",
        "        else:\n",
        "            items[new_key] = v\n",
        "    return items\n",
        "\n",
        "def safe_cast(val, to_type, default):\n",
        "    try:\n",
        "        return to_type(val)\n",
        "    except Exception:\n",
        "        return default\n",
        "\n",
        "def build_context(entry):\n",
        "    \"\"\"Build a flat context dict from a single entry in final_output.json, using all parameters.\"\"\"\n",
        "    live_data_str = entry.get(\"Live_data_from_frontend\", \"\")\n",
        "    parsed = parse_live_data(live_data_str)\n",
        "    user_info = parsed.get(\"user\", {})\n",
        "    product_info = parsed.get(\"product\", {})\n",
        "    metadata = flatten_dict(entry.get(\"metadata\", {}))\n",
        "\n",
        "    # Build context with all possible parameters\n",
        "    context = {}\n",
        "\n",
        "    # Add all user/product info\n",
        "    for k, v in user_info.items():\n",
        "        context[f\"user_{k}\"] = v\n",
        "    for k, v in product_info.items():\n",
        "        context[f\"product_{k}\"] = v\n",
        "\n",
        "    # Add all metadata (flattened)\n",
        "    for k, v in metadata.items():\n",
        "        context[f\"meta_{k}\"] = v\n",
        "\n",
        "    # Add top-level fields\n",
        "    context[\"user_input\"] = entry.get(\"user\", \"\").replace(\"User: \", \"\").strip()\n",
        "    context[\"gold_response\"] = entry.get(\"response\", \"\").replace(\"Bot: \", \"\").strip()\n",
        "\n",
        "    # Some fields for prompt logic (with safe casting)\n",
        "    context[\"orders\"] = safe_cast(user_info.get(\"orders\", 0), int, 0)\n",
        "    context[\"spent\"] = safe_cast(user_info.get(\"spent\", 0), int, 0)\n",
        "    context[\"refunds\"] = safe_cast(user_info.get(\"refunds\", 0), int, 0)\n",
        "    context[\"days_since_last\"] = safe_cast(user_info.get(\"days_since_last\", 0), int, 0)\n",
        "    context[\"email_verified\"] = str(user_info.get(\"email_verified\", \"False\")).lower() in (\"true\", \"1\", \"yes\")\n",
        "\n",
        "    context[\"product_name\"] = product_info.get(\"product_name\", \"Unknown Product\")\n",
        "    context[\"product_description\"] = product_info.get(\"product_description\", \"\")\n",
        "    context[\"product_price\"] = safe_cast(str(product_info.get(\"product_price\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"min_price_client\"] = safe_cast(str(product_info.get(\"min_price_client\", \"0\")).replace(\" INR\", \"\"), int, 0)\n",
        "    context[\"avg_inventory\"] = safe_cast(product_info.get(\"avg_inventory\", 0), int, 0)\n",
        "    context[\"product_tag\"] = product_info.get(\"product_tag\", \"\")\n",
        "    context[\"product_type\"] = product_info.get(\"product_type\", \"\")\n",
        "    context[\"images_count\"] = safe_cast(product_info.get(\"images_count\", 0), int, 0)\n",
        "    context[\"days_since_creation\"] = safe_cast(product_info.get(\"days_since_creation\", 0), int, 0)\n",
        "\n",
        "    # Metadata fields for prompt logic (with safe casting)\n",
        "    context[\"user_score\"] = safe_cast(metadata.get(\"user_score\", 0), float, 0)\n",
        "    context[\"bargain_score\"] = safe_cast(metadata.get(\"bargain_score\", 0), float, 0)\n",
        "    context[\"product_score\"] = safe_cast(metadata.get(\"product_score\", 0), float, 0)\n",
        "    context[\"admin_max_discount_from_min_price\"] = safe_cast(metadata.get(\"admin_max_discount_from_min_price\", 0), float, 0)\n",
        "    context[\"system_max_discount\"] = safe_cast(metadata.get(\"system_max_discount\", 0), float, 0)\n",
        "    context[\"max_round_count\"] = safe_cast(metadata.get(\"max_round_count\", 0), int, 0)\n",
        "    context[\"current_round\"] = safe_cast(metadata.get(\"current_round\", 0), int, 0)\n",
        "    context[\"previous_round_discount_given\"] = safe_cast(metadata.get(\"previous_round_discount_given\", 0), float, 0)\n",
        "    context[\"user_req\"] = safe_cast(metadata.get(\"user_req\", 0), float, 0)\n",
        "    context[\"current_discount\"] = safe_cast(metadata.get(\"current_discount\", 0), float, 0)\n",
        "    context[\"current_discount_price\"] = safe_cast(metadata.get(\"current_discount_price\", 0), float, 0)\n",
        "    context[\"round_discounts\"] = metadata.get(\"round_discounts\", {})\n",
        "\n",
        "    return context\n",
        "\n",
        "def get_messages(context):\n",
        "    # Calculate derived values\n",
        "    min_price_pct = (context['min_price_client'] / context['product_price']) * 100 if context['product_price'] > 0 else 0\n",
        "    refund_rate = (context['refunds'] / context['spent'] * 100) if context['spent'] > 0 else 0\n",
        "    current_price = context['product_price'] * (1 - context['current_discount']/100)\n",
        "    next_round = min(context['current_round'] + 1, context['max_round_count'])\n",
        "\n",
        "    # Get next round target discount if available\n",
        "    next_round_key = f'round_count{next_round}'\n",
        "    next_round_discount = context['round_discounts'].get(next_round_key, 'N/A')\n",
        "\n",
        "    # Parameter influence summary with detailed calculations\n",
        "    parameter_summary = f\"\"\"\n",
        "USER PROFILE\n",
        "- Orders: {context['orders']} (User Score: {context['user_score']:.1f})\n",
        "- Total Spent: ₹{context['spent']:,} (Refund Rate: {refund_rate:.1f}%)\n",
        "- Bargain Skill: {context['bargain_score']}/100\n",
        "- Days Since Last Purchase: {context['days_since_last']}\n",
        "\n",
        "PRODUCT STATUS\n",
        "- Price: ₹{context['product_price']:,} (Min Price: ₹{context['min_price_client']:,} = {min_price_pct:.1f}%)\n",
        "- Inventory: {context['avg_inventory']} units\n",
        "- Age: {context['days_since_creation']} days\n",
        "- Product Score: {context['product_score']:.1f}\n",
        "\n",
        "NEGOTIATION STATE\n",
        "- Round: {context['current_round']}/{context['max_round_count']} (Next: {next_round_discount}%)\n",
        "- Last Offer: {context['previous_round_discount_given']}% (₹{current_price:,.2f})\n",
        "- User Request: {context['user_req']}%\n",
        "- System Max: {context['system_max_discount']}%\n",
        "- Admin Max: {context['admin_max_discount_from_min_price']}%\n",
        "\n",
        "DISCOUNT CALCULATION FACTORS\n",
        "1. User Value (Score: {context['user_score']:.1f}/45)\n",
        "   - Tier: {'Low' if context['user_score'] < 15 else 'Medium' if context['user_score'] < 30 else 'High'}\n",
        "   - Impact: {0.5 if context['user_score'] < 15 else 1.0 if context['user_score'] < 30 else 1.5}x base discount\n",
        "\n",
        "2. Inventory Status: {context['avg_inventory']} units\n",
        "   - Level: {'Critical' if context['avg_inventory'] < 5 else 'Low' if context['avg_inventory'] < 20 else 'Normal'}\n",
        "   - Adjustment: {2 if context['avg_inventory'] < 5 else 1 if context['avg_inventory'] < 20 else 0.5}% bonus\n",
        "\n",
        "3. Product Age: {context['days_since_creation']} days\n",
        "   - Category: {'New' if context['days_since_creation'] < 30 else 'Old' if context['days_since_creation'] > 180 else 'Average'}\n",
        "   - Adjustment: {0 if context['days_since_creation'] < 30 else 0.5 if context['days_since_creation'] < 180 else 1}% bonus\n",
        "\n",
        "4. Bargain Score: {context['bargain_score']}/100\n",
        "   - Level: {'Weak' if context['bargain_score'] < 40 else 'Average' if context['bargain_score'] < 70 else 'Strong'}\n",
        "   - Impact: {0.5 if context['bargain_score'] < 40 else 1.0 if context['bargain_score'] < 70 else 1.5}x base discount\n",
        "\n",
        "5. Round Progression: Round {context['current_round']} of {context['max_round_count']}\n",
        "   - Expected Increase: {2 if context['current_round'] <= 2 else 1 if context['current_round'] <= 4 else 0.5}% from last offer\n",
        "\"\"\"\n",
        "\n",
        "    system_prompt = f\"\"\"\n",
        "You are an intelligent shopping assistant negotiating prices over multiple rounds.\n",
        "Your goal is to reach a deal while strategically managing discounts across all rounds.\n",
        "\n",
        "Rules:\n",
        "1. You're currently in Round {context['current_round']} of {context['max_round_count']}.\n",
        "2. Your maximum allowed discount is {context['system_max_discount']}% (Admin max: {context['admin_max_discount_from_min_price']}%).\n",
        "3. Don't jump straight to the highest discount — leave room for future rounds.\n",
        "4. Suggest a reasonable increase from the last offer: {context['previous_round_discount_given']}%.\n",
        "5. Always include: discount %, final price, optional negotiation invite.\n",
        "6. Respond with only one persuasive line — no extra text or explanation.\n",
        "7. Discount must be ≤ {context['system_max_discount']}% and ≥ previous offer.\n",
        "8. Consider user's value (score: {context['user_score']:.1f}), inventory ({context['avg_inventory']} units),\n",
        "   product age ({context['days_since_creation']} days), and bargain skill ({context['bargain_score']}/100).\n",
        "\"\"\"\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt.strip()},\n",
        "        {\"role\": \"user\", \"content\": parameter_summary.strip()}\n",
        "    ]\n",
        "\n",
        "def extract_discount(text):\n",
        "    \"\"\"Extract the discount percentage from the model's response (best effort).\"\"\"\n",
        "    match = re.search(r'(\\d+(\\.\\d+)?)\\s*%', text)\n",
        "    if match:\n",
        "        return float(match.group(1))\n",
        "    return None\n",
        "\n",
        "def generate_responses(input_file_path, output_file_path, limit=50):\n",
        "    with open(input_file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        input_data = json.load(f)\n",
        "    results = []\n",
        "    for idx, entry in enumerate(input_data[:limit]):\n",
        "        print(f\"Processing scenario {idx + 1}/{limit}\")\n",
        "        context = build_context(entry)\n",
        "        messages = get_messages(context)\n",
        "        prompt = tokenizer.apply_chat_template(messages, tokenize=False)\n",
        "        outputs = pipeline(\n",
        "            prompt,\n",
        "            max_new_tokens=100,\n",
        "            do_sample=True,\n",
        "            temperature=0.7,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "            pad_token_id=tokenizer.pad_token_id,\n",
        "        )\n",
        "        bot_response = outputs[0][\"generated_text\"][len(prompt):].strip()\n",
        "        discount_pred = extract_discount(bot_response)\n",
        "        # Append predicted discount to response\n",
        "        full_bot_response = f\"Bot: {bot_response}\"\n",
        "        if discount_pred is not None:\n",
        "            full_bot_response += f\" [Predicted Discount: {discount_pred}%]\"\n",
        "        # Copy original entry, update response and gold\n",
        "        updated_entry = entry.copy()\n",
        "        updated_entry[\"gold\"] = entry.get(\"response\", \"\")     # Original Bot response\n",
        "        updated_entry[\"response\"] = full_bot_response         # New model-generated response\n",
        "        results.append(updated_entry)\n",
        "    with open(output_file_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(results, f, indent=4, ensure_ascii=False)\n",
        "    print(f\"✅ Saved {len(results)} responses to {output_file_path}\")\n",
        "\n",
        "# Example usage (uncomment to run):\n",
        "generate_responses(\"final_output.json\", \"responses.json\", limit=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHV94ygbyVmQ",
        "outputId": "ac67656c-3c56-4510-bb61-72c7e6427852"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing scenario 1/10\n",
            "Processing scenario 2/10\n",
            "Processing scenario 3/10\n",
            "Processing scenario 4/10\n",
            "Processing scenario 5/10\n",
            "Processing scenario 6/10\n",
            "Processing scenario 7/10\n",
            "Processing scenario 8/10\n",
            "Processing scenario 9/10\n",
            "Processing scenario 10/10\n",
            "✅ Saved 10 responses to responses.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "92xSutdb4WEi"
      }
    }
  ]
}
